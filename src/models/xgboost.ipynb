{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7cadd9",
   "metadata": {},
   "source": [
    "## Training XGBoost model (Jasur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train = pd.read_csv(\"../data/X_train.csv\")\n",
    "X_val = pd.read_csv(\"../data/X_val.csv\")\n",
    "X_test = pd.read_csv(\"../data/X_test.csv\")\n",
    "\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\").squeeze()  \n",
    "y_val = pd.read_csv(\"../data/y_val.csv\").squeeze()\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\").squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_fast = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "X_combined = pd.concat([X_train_df, X_val_df], axis=0, ignore_index=True)\n",
    "y_combined = np.concatenate([y_train, y_val])\n",
    "\n",
    "print(f\"Combined dataset shape: {X_combined.shape}\")\n",
    "print(f\"Target shape: {y_combined.shape}\")\n",
    "print(f\"Total parameter combinations: {np.prod([len(v) for v in param_grid_fast.values()])}\")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2972e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up GridSearchCV...\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid_fast,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"Starting GridSearchCV at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "grid_search.fit(X_combined, y_combined)\n",
    "\n",
    "print(f\"GridSearchCV completed at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Score (neg_MSE): {grid_search.best_score_:.6f}\")\n",
    "print(f\"Best RMSE: {np.sqrt(-grid_search.best_score_):.6f}\")\n",
    "print(f\"Best Parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING FINAL MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "best_xgb.fit(\n",
    "    X_train_df, \n",
    "    y_train,\n",
    "    eval_set=[(X_val_df, y_val)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = best_xgb.predict(X_train_df)\n",
    "y_val_pred = best_xgb.predict(X_val_df)\n",
    "y_test_pred = best_xgb.predict(X_test_df)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, set_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{set_name} Set Metrics:\")\n",
    "    print(f\"  RMSE: {rmse:.6f}\")\n",
    "    print(f\"  MAE:  {mae:.6f}\")\n",
    "    print(f\"  R²:   {r2:.6f}\")\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, \"Training\")\n",
    "val_metrics = calculate_metrics(y_val, y_val_pred, \"Validation\") \n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE (Top 10)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_df.columns,\n",
    "    'importance': best_xgb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('XGBoost Model Analysis', fontsize=16)\n",
    "\n",
    "axes[0, 0].scatter(y_test, y_test_pred, alpha=0.6)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], \n",
    "                [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual')\n",
    "axes[0, 0].set_ylabel('Predicted')\n",
    "axes[0, 0].set_title(f'Actual vs Predicted (Test R² = {test_metrics[\"R2\"]:.3f})')\n",
    "\n",
    "residuals = y_test - y_test_pred\n",
    "axes[0, 1].scatter(y_test_pred, residuals, alpha=0.6)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 1].set_xlabel('Predicted')\n",
    "axes[0, 1].set_ylabel('Residuals')\n",
    "axes[0, 1].set_title('Residuals Plot')\n",
    "\n",
    "top_features = feature_importance.head(10)\n",
    "axes[1, 0].barh(range(len(top_features)), top_features['importance'])\n",
    "axes[1, 0].set_yticks(range(len(top_features)))\n",
    "axes[1, 0].set_yticklabels(top_features['feature'])\n",
    "axes[1, 0].set_xlabel('Importance')\n",
    "axes[1, 0].set_title('Top 10 Feature Importance')\n",
    "\n",
    "if hasattr(best_xgb, 'evals_result_'):\n",
    "    eval_results = best_xgb.evals_result_\n",
    "    epochs = len(eval_results['validation_0']['rmse'])\n",
    "    x_axis = range(0, epochs)\n",
    "    axes[1, 1].plot(x_axis, eval_results['validation_0']['rmse'], label='Validation')\n",
    "    axes[1, 1].set_xlabel('Epochs')\n",
    "    axes[1, 1].set_ylabel('RMSE')\n",
    "    axes[1, 1].set_title('Training History')\n",
    "    axes[1, 1].legend()\n",
    "else:\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Train': [train_metrics['RMSE'], train_metrics['MAE'], train_metrics['R2']],\n",
    "        'Validation': [val_metrics['RMSE'], val_metrics['MAE'], val_metrics['R2']],\n",
    "        'Test': [test_metrics['RMSE'], test_metrics['MAE'], test_metrics['R2']]\n",
    "    }, index=['RMSE', 'MAE', 'R²'])\n",
    "    \n",
    "    metrics_df.plot(kind='bar', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Metrics Comparison')\n",
    "    axes[1, 1].set_ylabel('Score')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 5 PARAMETER COMBINATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_results = results_df.nlargest(5, 'mean_test_score')[\n",
    "    ['mean_test_score', 'std_test_score', 'params']\n",
    "]\n",
    "\n",
    "for idx, (_, row) in enumerate(top_results.iterrows(), 1):\n",
    "    print(f\"\\n{idx}. Score: {row['mean_test_score']:.6f} (±{row['std_test_score']:.6f})\")\n",
    "    print(f\"   Parameters: {row['params']}\")\n",
    "\n",
    "import os\n",
    "os.makedirs('/kaggle/working', exist_ok=True)\n",
    "\n",
    "best_xgb.save_model('/kaggle/working/best_xgboost_model.json')\n",
    "print(f\"\\nBest model saved as '/kaggle/working/best_xgboost_model.json'\")\n",
    "\n",
    "results_summary = {\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'best_score': grid_search.best_score_,\n",
    "    'train_metrics': train_metrics,\n",
    "    'val_metrics': val_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'feature_importance': feature_importance.head(20).to_dict()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('/kaggle/working/xgboost_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2, default=str)\n",
    "print(\"Results summary saved as '/kaggle/working/xgboost_results.json'\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"GRID SEARCH COMPLETE!\")\n",
    "print(f\"Best model RMSE on test set: {test_metrics['RMSE']:.6f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac101ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
